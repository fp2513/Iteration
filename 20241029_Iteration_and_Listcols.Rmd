---
title: "20241029_Iteration_and_Listcols"
output: github_document
date: "2024-10-29"
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
```

We write a function because we would do the same basic code over and over again. Process doing over and over is iterations. Take advantage of the formal structure 

Loop functions (avoid keeping track input / output list), easier to read 

Map rather than a for loop (not looking inside a for loop to look for index, instead here is the function that i have and here is input / output)

Process:
1. start with single working example 
2. change into a function 
3. re-write into a map statement 
(do not immediately start try writing a mapping statement)

Listcols --> 
lists are just collections of things 
not a dataframe (completely arbitary into a list)
Dataframes are a fancy / specific list 
Lists can also contain lists (there are lots of stuff to keep track of, if can keep organised into datafram it would be really helpful, also sub-elements (there are 1000 weather station, where each weather station has its own collection of analyses), works well for this kind of iterative analysis) 

# Here's some lists

Can do something inside the list (define a vector)
Different sorts of objects that can all exist in a single list
```{r}
l = list(
  vec_numeric = 1:4, #1 - 4
  unif_sample = runif(100), #100 numbers 
  mat = matrix(1:8, nrow = 2, ncol = 4, byrow = TRUE),
  summary = summary(rnorm(1000))
)

l$mat
```

notation l$mat can pull out from list (not the most ideal with $ but can) or can l[["mat"]] with two square brackets

```{r}
l[["mat"]]

l[["mat"]][1, 3] #in mat list find either 

l[[1]] #pull the first object from list
```

```{r}
list_norm = 
  list(
    a = rnorm(20, 0, 5),
    b = rnorm(20, 4, 5),
    c = rnorm(20, 0, 10),
    d = rnorm(20, 4, 10)
  )

list_norm[["b"]] #can pull specific one
#list of 4 samples from 4 differnet normal dis
```

Now have thees 4 samples and want to compute the mean and sd of each of the norm dis (write a function for mean and standard dev)

```{r}
mean_and_sd = function(x) {
  
  mean_x = mean(x)
  sd_x = sd(x)
  
  out_df = 
    tibble(
      mean = mean_x, 
      sd = sd_x
    )
  
  return(out_df)
}

```

We can use this function to make mean and sd of all samples

```{r}
mean_and_sd(list_norm[["a"]])
mean_and_sd(list_norm[["b"]])
mean_and_sd(list_norm[["c"]])
mean_and_sd(list_norm[["d"]])
```

To write 4 rows at once can click shift option then highlight the rows that i want to type on

But imagine there are more than 4 samples, what if had 10000s of samples then would be very difficult. Can create a for loop for this 

## Use a for loop 

Create an output list, and run a for loop 

```{r}
#we are creating an output with 4 spots in it 

output = vector("list", length = 4)

for (i in 1:4) {
  
  output[[i]] = mean_and_sd(list_norm[[i]])
  
}
```

Got a list of normals, there are 4 lists and for any one of those i want to apply mean and sd. and now i am creating an output list to catch each of the outputs separately 

if list_norm had 1000 entries to it can still work (rather than keeping track of each index myself and typing it all out)

But sometimes inside the for loop can get complicated, so people use map statement instead 

## Do same thing but with map statement instead

similar to for loop 

what is the input list that i want and what is the function that i want to apply every time to the input 

```{r}
output = map(list_norm, mean_and_sd)
```

Can do some other things easily 
i want to compute this function across this range of inputs 

```{r}
output = map(list_norm, median)
```

```{r}
output = map_dbl(list_norm, IQR)
#since IQR will be a collection of numbers 
```

There are some useful variants to the basic map function if you know what kind of output youâ€™re going to produce. Below we use map_dbl because median outputs a single numeric value each time; the result is a vector instead of a list. Using the .id argument keeps the names of the elements in the input list.

```{r}
output = map_dbl(list_norm, mean_and_sd) %>% 
  bind_rows()

output = map_dfr(list_norm, mean_and_sd)

```

## List Columns 

since everything is just floating around at the moment; can create a list column

```{r}
listcol_df = 
  tibble(
    name = c("a", "b", "c", "d"),
    samp = list_norm
  )

listcol_df
```

Since it is a dataframe, filter and select still work on it 

currently we are making a list of length 4 naming from a to d (like a list of 4 baskets)
then see that in each of the 4 baskets there is another list of 20 (like 20 apples)

So a list of apples inside a list baskets

```{r}
listcol_df %>% filter(
  name %in% c("a", "b")
)

listcol_df %>% 
  select(-samp)
```

```{r}
listcol_df[["samp"]][["a"]]
```

list_norm is a list of normal distributions

```{r}
mean_and_sd(listcol_df[["samp"]][["a"]])
mean_and_sd(listcol_df[["samp"]][["b"]])

map(listcol_df[["samp"]], mean_and_sd)
```

# Add a list column 

```{r}
listcol_df %>% 
  mutate(
    output = map(samp, mean_and_sd)
  )
```

Now added a new column called mean and sd that goes into my list of 20 (apples) and calculates that mean and sd and it becomes a new list in a new column. List of 4 mean and sd 

```{r}
listcol_df %>% 
  mutate(
    output = map(samp, mean_and_sd),
    iqr = map_dbl(samp, IQR)) %>% 
  select(-samp) %>% 
  unnest(output)
```

# Now with NSDUH dataframe

find this code on the functions_source 

```{r}
NSDUH_import = function(html, table_num, drug_name) {
  
  drug_df = 
    html %>% 
    html_table() %>% 
    nth(table_num) %>% 
    slice(-1) %>% 
    select(-contains("P Value"))
  
  return(drug_df)
}
```

We need to import the html, and then extract the correct tables

```{r}
nsduh_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html = read_html(nsduh_url)
```

```{r}
NSDUH_import(html = nsduh_html, table_num = 1)
NSDUH_import(html = nsduh_html, table_num = 4)
NSDUH_import(html = nsduh_html, table_num = 5)
```


Learning Check to have a dataframe that has the drug name, then telling me whcih table number it is, then the table itself in a dataframe

Define first a tibble of things that i want 

```{r}
nsduh = 
  tibble(
    drug = c("marj", "cocaine", "herion"), 
    table_n = c(1, 4, 5)
  ) %>% 
  mutate(table = map(table_n, NSDUH_import, html = nsduh_html)) %>% 
  unnest(table) #unnest table to see the entire dataframe (expands out the list)

nsduh

nsduh %>% filter(State == "New York") #can continue to do all the tidyverse things that we have learnt beforehand
```

## Weather data 

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USW00022534 = "Molokai_HI",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

So far seen creating a list column by hand or by function

```{r}
weather_nest = 
  weather_df %>% 
  nest(data = date:tmin)

weather_nest
```

nesting everything from date to tmin columns into a new column called data

```{r}
weather_nest[["data"]]
```
Giving separated out based on the id 

```{r}
weather_nest[["data"]][[1]]
```

Let's try regressing tmax on tmin

```{r}
lm(tmax ~ tmin, data = weather_nest[["data"]][[1]])
lm(tmax ~ tmin, data = weather_nest[["data"]][[2]])
lm(tmax ~ tmin, data = weather_nest[["data"]][[3]])
```

```{r}
weather_nest %>% 
  mutate(model_fit = map(data, \(x) lm(tmax ~ tmin, data = x))) %>% 
  pull(model_fit)

#x is the thing that im mapping across and plug it in each time into the function lm
```
Fit weather station specific regressions 
